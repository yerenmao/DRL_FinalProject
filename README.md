# DRL_FinalProject

## Group Members

- Shun Ying Chen
- Po Jen Ko
- Tzu Hung Huang
- Li Chen Kao

## Introduction

Urban traffic congestion remains a major challenge in modern cities, leading to
increased travel times, fuel consumption, and greenhouse gas emissions. Traditional
traffic signal control systems often rely on fixed schedules or handcrafted rules,
which are not flexible enough to adapt to dynamic and unpredictable traffic patterns.
These limitations motivate the need for more intelligent and adaptive control
strategies.

This project explores a reinforcement learning-based approach to traffic signal
control using a multi-agent framework. Leveraging the SUMO simulator, we train
intersection agents to adapt their policies based on real-time traffic conditions.
Through extensive simulations, we demonstrate that learning-based control can
significantly improve traffic flow and reduce CO2 emissions compared to rule-
based methods

## SUMO environment

https://eclipse.dev/sumo/

## Methods

- Tabular Q-learning
- Deep Q-Networks (DQN)
- IMPALA (Importance Weighted Actor-Learner Architecture)
- Proximal Policy Optimization (PPO)


